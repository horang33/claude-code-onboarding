# Block 1: Experience - "이게 된다고?" (~15분)

> 역할별 Before/After 데모. "와, 이걸 이렇게 할 수 있어?" 체감이 목표.

---

## EXPLAIN

이 블록에서는 Claude Code로 **실제 업무**를 처리하는 모습을 직접 체험합니다.
각 데모는 "기존 방식(Before)"과 "Claude Code 방식(After)"을 비교합니다.

핵심 메시지: **프롬프트 하나로 30분짜리 작업이 2분에 끝납니다.**

---

## EXECUTE

### 디자이너 트랙

#### 데모 1: Figma 디자인 파일 분석

**Before**: Figma에서 페이지를 하나씩 열어가며 컴포넌트 사용 현황을 수동 정리.
**After**: Claude Code에 아래 한 줄을 입력합니다.

```
Figma 파일 [URL]의 메타데이터를 확인하고, 사용된 컴포넌트 목록을 정리해줘.
```

> Figma MCP가 연결되어 있다면 실제 파일 URL을 넣어보세요.
> 연결되어 있지 않다면 아래 시뮬레이션을 해보세요:

```
내가 만약 Figma 디자인 시스템 파일을 연결했다고 가정하고,
일반적인 디자인 시스템에 포함되는 컴포넌트 목록을 구조화해서 정리해줘.
카테고리(Foundation, Component, Pattern)별로 나눠줘.
```

#### 데모 2: 디자인 시스템 정합성 체크

**Before**: 스타일 가이드 문서와 실제 디자인 파일을 번갈아 보며 불일치 찾기.
**After**:

```
아래 디자인 토큰 목록을 기준으로, 일반적으로 발생하는 정합성 문제 유형을 정리해줘:
- Primary: #FF6F61
- Secondary: #4A90D9
- Text: #333333
- Background: #FFFFFF
- Spacing: 4px 기반 (4, 8, 12, 16, 24, 32, 48)
- Typography: Pretendard (14/20, 16/24, 20/28, 24/32)
```

#### 데모 3: 모호한 요청 vs 명확한 요청

**Before**: "이 화면 좀 봐줘" → 뭘 봐달라는 건지 모호.
**After**: Claude Code의 AskUserQuestion 기능을 체험합니다.

```
이 모바일 앱의 온보딩 화면을 리뷰해줘
```

Claude가 되물을 겁니다: "어떤 관점으로 리뷰할까요?"
이것이 **좋은 AI 협업**의 핵심입니다 — AI가 스스로 명확화 질문을 합니다.

---

### 리서처 트랙

#### 데모 1: 인터뷰 트랜스크립트 분석

**Before**: 녹취록을 읽으며 포스트잇에 핵심 발견을 수동 정리. 30분 인터뷰 = 2시간 분석.
**After**: Claude Code에 아래를 입력합니다.

```
아래 인터뷰 녹취록을 분석해줘.
- 핵심 발견 5개 (인용문 포함)
- 감정 변화 흐름
- 숨겨진 니즈 (명시적으로 말하지 않았지만 추론 가능한 것)

[녹취록 파일 경로 또는 텍스트 붙여넣기]
```

> 실제 녹취록이 없다면 아래 시뮬레이션을 해보세요:

```
30대 직장인 사용자가 가구 구매 경험에 대해 인터뷰한 내용을 예시로 만들고,
그 예시를 바로 분석해줘.
핵심 발견, 감정 흐름, 숨겨진 니즈를 구분해서 정리해줘.
```

#### 데모 2: Notion 리서치 리포지토리 업데이트

**Before**: 분석 결과를 Notion에 수동으로 복붙, 태그 달기, 링크 연결.
**After**:

```
Notion에서 "리서치 인사이트" 페이지를 검색하고, 어떤 내용이 있는지 요약해줘.
```

> Notion MCP가 연결되어 있다면 실제로 실행됩니다.
> 연결되어 있지 않다면 시뮬레이션:

```
UX 리서치 팀의 인사이트 리포지토리를 Notion에 구성한다면
어떤 데이터베이스 구조(속성)가 필요한지 제안해줘.
```

#### 데모 3: 모호한 요청 vs 명확한 요청

**Before**: "이 데이터 좀 분석해줘" → 뭘 분석하라는 건지 모호.
**After**: Claude Code의 AskUserQuestion 기능을 체험합니다.

```
이 설문조사 결과를 분석해줘
```

Claude가 되물을 겁니다: "어떤 분석을 원하시나요?"
이것이 **좋은 AI 협업**의 핵심입니다 — AI가 스스로 명확화 질문을 합니다.

---

### PM 트랙

#### 데모 1: 제품 스펙 초안 작성

**Before**: 회의 노트를 보며 PRD를 수동으로 정리. 요구사항 빠뜨리기 일쑤.
**After**: Claude Code에 아래를 입력합니다.

```
아래 회의 노트를 기반으로 PRD 초안을 작성해줘.
- 기능 개요
- 사용자 스토리 3개
- 성공 지표 (KPI)
- 엣지 케이스

회의 노트: "장바구니에서 선물하기 기능 추가. 받는 사람 주소 입력, 메시지 카드 선택, 포장 옵션. 결제는 기존 플로우 재사용. 런칭은 다음 분기."
```

#### 데모 2: 경쟁사 빠른 분석

**Before**: 경쟁사 앱을 하나씩 스크린샷 찍고 엑셀에 정리. 반나절 소요.
**After**:

```
"당근마켓", "번개장터", "중고나라" 3개 서비스의 중고거래 플로우를 비교 분석해줘.
항목: 상품 등록 단계 수, 가격 제안 방식, 안전결제 유무, 채팅 기능.
비교 테이블로 정리해줘.
```

#### 데모 3: 모호한 요청 vs 명확한 요청

**Before**: "이 기능 기획해줘" → 범위도 대상도 모호.
**After**: Claude Code의 AskUserQuestion 기능을 체험합니다.

```
알림 기능을 개선해줘
```

Claude가 되물을 겁니다: "어떤 종류의 알림인가요? 개선 목표가 무엇인가요?"
이것이 **좋은 AI 협업**의 핵심입니다 — AI가 스스로 명확화 질문을 합니다.

---

## QUIZ

### 퀴즈 1

```
질문: 방금 체험한 3가지 데모의 공통점은 무엇인가요?
옵션:
  A) 코딩 지식이 필요했다
  B) 자연어로 요청하면 AI가 구조화된 결과를 만들어줬다
  C) 특별한 플러그인 설치가 필요했다
정답: B
해설: Claude Code의 핵심은 "자연어 → 구조화된 결과"입니다.
      코딩 지식 없이도 복잡한 분석과 정리를 자동화할 수 있습니다.
```

### 퀴즈 2

```
질문: 데모 3에서 Claude가 되물은 이유는?
옵션:
  A) 에러가 발생해서
  B) 요청이 모호해서 더 좋은 결과를 위해 명확화가 필요해서
  C) 해당 기능을 지원하지 않아서
정답: B
해설: AI는 모호한 요청보다 명확한 요청에 훨씬 좋은 결과를 냅니다.
      Claude Code는 AskUserQuestion으로 사용자에게 되물어 요청을 명확히 합니다.
      이것은 버그가 아니라 "좋은 AI 협업"의 시작입니다.
```
